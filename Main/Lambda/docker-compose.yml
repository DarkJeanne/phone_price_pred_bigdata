version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: echo "ruok" | nc localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka
    ports:
      - "${KAFKA_BOOTSTRAP_SERVERS_EXTERNAL_PORT:-9094}:9094" # KAFKA_BOOTSTRAP_SERVERS_EXTERNAL_PORT from .env
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://kafka:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://${KAFKA_BROKER_INTERNAL:-kafka:9092},EXTERNAL://localhost:${KAFKA_BOOTSTRAP_SERVERS_EXTERNAL_PORT:-9094}
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    healthcheck:
        test: "kafka-topics --bootstrap-server localhost:9092 --list || exit 1" # Runs inside container
        interval: 30s
        timeout: 10s
        retries: 5

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: unless-stopped
    ports:
      - "${HDFS_NAMENODE_WEBUI_PORT:-9870}:9870"
      - "9000:9000" # FS port for internal and external if localhost is used
    volumes:
      - hadoop_namenode_data:/hadoop/dfs/name
    environment:
      CLUSTER_NAME: hadoop-cluster
      HDFS_CONF_dfs_replication: 1
    env_file: .env # To pick HDFS_NAMENODE_WEBUI_PORT if defined there

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: unless-stopped
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode_data:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870" # Waits for namenode UI

  hbase-master:
    image: bde2020/hbase-master:2.0.0-hbase2.2.3
    container_name: hbase-master
    restart: unless-stopped
    ports:
      - "${HBASE_MASTER_WEBUI_PORT:-16010}:16010"
      - "${HBASE_THRIFT_PORT_EXTERNAL:-9090}:9090"
    depends_on:
      namenode:
        condition: service_started # Basic start, HBase has its own checks
      datanode:
        condition: service_started
      zookeeper:
        condition: service_healthy
    environment:
      HBASE_CONF_hbase_rootdir: ${HDFS_NAMENODE_URI_INTERNAL:-hdfs://namenode:9000}/hbase
      HBASE_CONF_hbase_cluster_distributed: "true"
      HBASE_CONF_hbase_zookeeper_quorum: ${HBASE_ZOOKEEPER_QUORUM_INTERNAL:-zookeeper}
      HBASE_CONF_hbase_zookeeper_property_clientPort: ${HBASE_ZOOKEEPER_PORT_INTERNAL:-2181}
    env_file: .env

  hbase-regionserver:
    image: bde2020/hbase-regionserver:2.0.0-hbase2.2.3
    container_name: hbase-regionserver
    restart: unless-stopped
    ports:
      - "16030:16030" # RegionServer WebUI
    depends_on:
      - hbase-master
    environment:
      HBASE_CONF_hbase_master_port: "16000" # Port hbase-master is listening on
      HBASE_CONF_hbase_master: "hbase-master:16000" # Host and port for hbase-master
      HBASE_CONF_hbase_zookeeper_quorum: ${HBASE_ZOOKEEPER_QUORUM_INTERNAL:-zookeeper}
      HBASE_CONF_hbase_zookeeper_property_clientPort: ${HBASE_ZOOKEEPER_PORT_INTERNAL:-2181}
      HBASE_CONF_hbase_rootdir: ${HDFS_NAMENODE_URI_INTERNAL:-hdfs://namenode:9000}/hbase
    env_file: .env

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3 # Ensure this hadoop version is compatible with your HDFS
    container_name: spark-master
    ports:
      - "${SPARK_MASTER_WEBUI_PORT:-8081}:8080"
      - "7077:7077"
    environment:
      SPARK_PUBLIC_DNS: localhost # For UI links
    volumes:
      - ./Batch_layer:/opt/spark/apps/batch_layer
      - ./ML_operations:/opt/spark/apps/ml_ops
      - ./transform.py:/opt/spark/apps/transform.py
    env_file: .env

  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8082:8081" # Each worker UI will be on a different port if you scale
    environment:
      SPARK_MASTER: ${SPARK_MASTER_URL_INTERNAL:-spark://spark-master:7077}
    volumes: # Mount same app locations so worker can access code
      - ./Batch_layer:/opt/spark/apps/batch_layer
      - ./ML_operations:/opt/spark/apps/ml_ops
      - ./transform.py:/opt/spark/apps/transform.py
    env_file: .env

  realtime_flask_app:
    build:
      context: ./Main/Lambda/real_time_web_app(Flask)
      dockerfile: Dockerfile
    container_name: realtime_flask_app
    restart: unless-stopped
    ports:
      - "${FLASK_APP_PORT:-5001}:${FLASK_APP_PORT:-5001}"
    volumes:
      - ./real_time_web_app(Flask):/app # For dev live reload
    env_file: .env
    depends_on:
      hbase-master:
        condition: service_started 
      kafka:
        condition: service_healthy

  data_ingestion_pipeline:
    build:
      context: ./Main/Lambda
      dockerfile: data_ingestion_pipeline.Dockerfile
    container_name: data_ingestion_pipeline
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      namenode:
        condition: service_started
      datanode:
        condition: service_started
    env_file: .env
    volumes:
      - ./producer.py:/opt/app/producer.py
      - ./Stream_data:/opt/app/Stream_data
      - ./Batch_layer:/opt/app/Batch_layer
    networks:
      - default

  stream_processor:
    build:
      context: ./Main/Lambda
      dockerfile: stream_processor.Dockerfile
    container_name: stream_processor
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      hbase-master: # Hoặc hbase-regionserver nếu kết nối trực tiếp
        condition: service_started # HBase có thể cần thời gian để sẵn sàng hoàn toàn
    env_file: .env # Để đọc cấu hình Kafka, HBase
    volumes:
      # Nếu model lớn hoặc cần cập nhật thường xuyên mà không muốn build lại image
      # - ./ML_operations:/opt/app/ML_operations 
      - ./Stream_layer:/opt/app/Stream_layer # Mount để dev tiện hơn
    networks:
      - default

  # Service để chạy Spark batch job (spark_tranformation.py)
  # Service này sẽ chạy spark-submit và thoát khi job hoàn thành.
  spark_batch_job_runner:
    image: bde2020/spark-master:3.3.0-hadoop3.3 # Sử dụng cùng image với spark-master hoặc một image có spark-submit
    container_name: spark_batch_job_runner
    # restart: no # Hoặc on-failure. Không nên là always/unless-stopped cho job chạy một lần
    volumes:
      - ./Batch_layer:/opt/spark/apps/batch_layer # spark_tranformation.py and spark_job_requirements.txt are here
      - ./ML_operations/xgb_model.pkl:/opt/spark/apps/xgb_model.pkl # Model for spark_tranformation.py
      - ./transform.py:/opt/spark/apps/transform.py # transform.py for --py-files
      - ./.env:/opt/spark/apps/.env # .env file if needed by pip install or scripts during setup before spark
    env_file:
      - ./.env # Load .env into the service's environment for Spark job variables
    command: >
      /bin/bash -c "
        echo 'spark_batch_job_runner: Installing dependencies...';
        pip install -r /opt/spark/apps/batch_layer/spark_job_requirements.txt;
        echo 'spark_batch_job_runner: Submitting Spark job...';
        cd /opt/spark/apps && \\
        spark-submit \\
          --master ${SPARK_MASTER_URL_INTERNAL:-spark://spark-master:7077} \\
          --deploy-mode client \\
          --py-files transform.py \\
          batch_layer/spark_tranformation.py;
        echo 'spark_batch_job_runner: Spark job finished or submitted.';
      "
    depends_on:
      spark-master:
        condition: service_started
      namenode:
        condition: service_started
      # datanode is implied by namenode for HDFS readiness for writing, but explicit doesn't hurt
      # datanode: 
      #   condition: service_started 
    networks: # Ensure it's on the same network as other services
      - default

  # Service để chạy Spark Streaming job (TẠM THỜI VÔ HIỆU HÓA)
  # spark_streaming_job_runner:
  #   image: bde2020/spark-master:3.3.0-hadoop3.3 # Hoặc image có spark-submit và các dependencies cần thiết
  #   container_name: spark_streaming_job_runner
  #   restart: unless-stopped # Vì streaming job thường chạy liên tục
  #   command: |
  #     /bin/bash -c "
  #       echo 'Waiting for Spark Master and Kafka to be ready for Streaming job...'; 
  #       # Có thể thêm cơ chế đợi Kafka topic được tạo hoặc HDFS sẵn sàng nếu cần
  #       # sleep 20;
  #       spark-submit \
  #         --master ${SPARK_MASTER_URL_INTERNAL:-spark://spark-master:7077} \
  #         --deploy-mode client \
  #         --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:10.2.0 # Thêm package Kafka và MongoDB cho Spark
  #         # Nếu ghi Parquet/ORC cần thư viện tương ứng hoặc Hadoop client đầy đủ
  #         /opt/spark/apps/batch_layer/spark_streaming_processor.py; 
  #       echo 'Spark Streaming job submitted.'; 
  #     "
  #   depends_on:
  #     spark-master:
  #       condition: service_started
  #     kafka:
  #       condition: service_healthy
  #     namenode: # Nếu ghi HDFS
  #       condition: service_started
  #     datanode: # Nếu ghi HDFS
  #       condition: service_started
  #     mongodb: # Nếu ghi MongoDB
  #       condition: service_healthy
  #   volumes:
  #     - ./Batch_layer:/opt/spark/apps/batch_layer
  #     # Mount các thư mục khác nếu streaming job cần
  #   env_file: .env
  #   networks:
  #     - default

volumes:
  hadoop_namenode_data:
  hadoop_datanode_data:

# networks:
#   default:
#     driver: bridge # Mặc định nếu không khai báo 